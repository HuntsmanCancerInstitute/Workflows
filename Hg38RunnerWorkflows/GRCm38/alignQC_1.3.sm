#Define the resources from the config file

## Base name to prepend on all files
name = config["name"]

## Gzipped Fastq files
fastqReadOne = config["fR"]
fastqReadTwo = config["sR"]

## For messaging
email = config["email"]

# For ReadCov calc, smallest, for calc fraction with X coverage
regionsForRC= config["rcBed"]

# For OnTarget calc, largest
regionsForOnTarget= config["otBed"]

## Params
allThreads = int(config["threads"])
halfThreads = int(round(allThreads/2,0))
allMemory = config["memory"]

## Apps
useq = "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/USeq/Apps"
cutadapt = "/uufs/chpc.utah.edu/common/HIPAA/u0028003/.local/bin/cutadapt"
bwa = "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/Bwa/bwa-0.7.12/bwa"
picard= "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/Picard/2.1.1/picard.jar"
ucsc= "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/UCSC/08-Mar-2016"
samtools= "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/Samtools/1.3.1/bin/samtools"
samblaster="/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/Samblaster/0.1.22/samblaster"
gatk = "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/GATK/3.7-0-gcfedb67/GenomeAnalysisTK.jar"

## Resources
indexFasta= "/uufs/chpc.utah.edu/common/HIPAA/u0028003/HCINix/MM10Ref/FastaIndex/Mus_musculus.GRCm38.dna.primary_assembly.fa"

## Languages
java= "/uufs/chpc.utah.edu/common/HIPAA/u0028003/BioApps/Java/1.8.0_65/bin/java"

requiredFiles = [fastqReadOne, fastqReadTwo, regionsForRC, regionsForOnTarget, useq, cutadapt, bwa, picard, ucsc, samtools, samblaster, gatk, indexFasta, java]


############# Messaging ##############
onerror:
    shell( "dir=`pwd`; mail -s \"Failed: {name} ($dir)\" {email} < {log}; sleep 4s")
onsuccess:
    shell( "dir=`pwd`; mail -s \"Complete: {name} ($dir)\" {email} < {log}; sleep 4s")

############# Rules ##############

# One rule to rule them all
rule Cleanup:
    input:
        name+ "_uniObReadCov.bw",
        name+ "_FastqCount.json.gz"
    shell:
    	"mkdir Log Json ReadCov && "
    	"gzip *log && "
    	"mv *log.gz Log/ && "
    	"mv *json.gz Json/ && "
    	"mv *bed.gz ReadCov/ && "
    	"mv *bw ReadCov/ && "
    	"mv *perRegionCoverageStats.txt.gz ReadCov/ && "
	"rm -rf *_MPA *_SAE snappy* && "
    	"echo [`date`] rule Cleanup: COMPLETE; echo" 
        
############# Fastq and resources check ##############

# Uses ls to check if all the required resources are present 
rule CheckResources:
    output:
        temp(name+ "_CheckResources.complete")
    log:
        name+ "_CheckResources.log"
    shell:
        "ls {requiredFiles} &> {log} && touch {output} && "
        "echo [`date`] rule CheckResources: COMPLETE ; echo"

# Uses gunzip -t to check the integrity of the xxx.gz files in the working directory
rule CheckGzipFiles:
    output:
        temp( name+ "_CheckGzipFiles.complete")
    log:
        name+ "_CheckGzipFiles.log"
    shell:
        "gunzip -tv *.gz &> {log} && touch {output} && "
        "echo [`date`] rule CheckGzipFiles: COMPLETE; echo" 
        
# Count the number of fastq records, used in QC
rule FastqCount:
    output:
        name+ "_FastqCount.json.gz"
    shell:
        "x=$(gunzip -c {fastqReadOne} | wc -l | tr -d \" \") && "
        "y=$(($x/2)) && "
        "echo \{{ > {name}_FastqCount.json && "
        "echo \\\"numberFastqReads\\\": $y >> {name}_FastqCount.json && "
        "echo \}} >> {name}_FastqCount.json && "
        "gzip {name}_FastqCount.json && "
        "echo [`date`] rule FastqCount: COMPLETE; echo "

############# Alignment ###############

# Cutadapt to remove the adapters from the fastq
rule CutAdapt:
    input:
        name+ "_CheckResources.complete",
        name+ "_CheckGzipFiles.complete"
    output:
        fq1 = name+ "_1.fastq",
        fq2 = name+ "_2.fastq"
    threads:
        allThreads
    log:
        name+ "_CutAdapt.log"
    shell:
        "{cutadapt} --cores=0 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT "
        "-o {output.fq1} -p {output.fq2} {fastqReadOne} {fastqReadTwo} &> {log} && "
        "echo [`date`] rule CutAdapt: COMPLETE; echo"

# The BIG pipe for aligning standard paired fastq
rule Align:
    input:
        res = name+ "_CheckResources.complete",
        fq1 = name+"_1.fastq",
        fq2 = name+"_2.fastq"
    output:
        temp( name+ "_raw.bam")
    log:
        name+ "_Align.log"
    params: 
        "\"@RG\\tID:" +name+ "\\tPL:ILLUMINA\\tLB:" +name+ "\\tSM:" +name+ "\\tCN:U2BSR\\tPU:" +name+ "\""
    threads:    
        allThreads
    shell:
        # Align with bwa mem
        "{bwa} mem -v 1 -t {threads} -R {params} {indexFasta} {input.fq1} {input.fq2} 2>> {log} | "

        # Mark duplicates
        "{samblaster} 2>> {log} | "

        # Write as bam
        "{samtools} view -Sb - 2>> {log} > {output} && "
        "echo [`date`] rule Align: COMPLETE; echo" 

# Fix mate info and sort, not always necessary but doesn't hurt
rule FixMateInformation:
    input:
        name+ "_raw.bam"
    output:
        bam = temp( name+ "_unfiltered.bam"),
	bai = temp( name+ "_unfiltered.bai")
    threads:
        allThreads
    log:
        name+ "_FixMateInformation.log"
    shell:
        "{java} -Xmx{allMemory} -jar {picard} FixMateInformation CREATE_INDEX=true SO=coordinate "
        "MAX_RECORDS_IN_RAM=5000000 TMP_DIR=. VALIDATION_STRINGENCY=SILENT INPUT={input} "
        "OUTPUT={output.bam} &> {log} && "
        "echo [`date`] rule FixMateInformation: COMPLETE; echo" 


############# Bam Filtering ##############

# Use the SamAlignmentExtractor to remove poor quality alignments but keep off target in pass output for SV calling
rule SamAlignmentExtractor:
    input:
        bam = name+ "_unfiltered.bam",
        bai = name+ "_unfiltered.bai"
    output:
        dir = temp(name+ "_SAE"),
        bam = temp(name+ "_sae.bam"),
        bai = temp(name+ "_sae.bai"),
        json = name+ "_samAlignmentExtractor.json.gz"
    params:
        "-q 20 -a 0.5 -d -f"
    threads:
        allThreads
    log:
        name+ "_SamAlignmentExtractor.log",
    shell:
        "{java} -Xmx{allMemory} -jar {useq}/SamAlignmentExtractor {params} -s {output.dir} -b {input.bam} "
        "-r {regionsForOnTarget} -j {output.json} &> {log} && "
        "mv {output.dir}/*_passSAE.bam {output.bam} &>> {log} && "
        "mv {output.dir}/*_passSAE.bai {output.bai} &>> {log} && "
        "echo [`date`] rule SamAlignmentExtractor: COMPLETE; echo" 

# Remove duplicates
rule RemoveDuplicates:
    input:
        name+ "_sae.bam"
    output:
        bam = name+ "_final.bam",
        bai = name+ "_final.bai",
        metrics = temp(name+ "_RemoveDuplicates.metrics")
    threads:
        allThreads
    log:
        name+ "_RemoveDuplicates.log"
    shell:
        "{java} -Xmx{allMemory} -jar {picard} MarkDuplicates REMOVE_DUPLICATES=true TMP_DIR=. VERBOSITY=ERROR "
        "VALIDATION_STRINGENCY=SILENT MAX_RECORDS_IN_RAM=5000000 CREATE_INDEX=true "
        "METRICS_FILE={output.metrics} INPUT={input} OUTPUT={output.bam} &> {log} && "
        "echo [`date`] rule RemoveDuplicates: COMPLETE; echo" 
        
############# Alignment QC ##############

# QC, Merge paired alignments for unique observation QC
rule MergePairedAlignments:
    input:
        name+ "_final.bam"
    output:
        dir = temp(name+ "_MPA"),
        json = name+ "_mergePairedAlignments.json.gz"   
    threads:
        allThreads
    log:
        name+ "_MergePairedAlignments.log"
    shell:
        "{java} -Xmx{allMemory} -jar {useq}/MergePairedAlignments -b {input} -d {output.dir} "
        "-j {output.json} -t {halfThreads} &> {log} && "
        "echo [`date`] rule MergePairedAlignments: COMPLETE; echo" 

# QC, Generate read coverage QC metrics and bed pass fail files with Sam2USeq
rule Sam2USeq:
    input:
        name+ "_MPA"
    output:
        useq = temp(name+ "_uniObReadCov.useq"),
        cs = name+ "_perRegionCoverageStats.txt.gz",
        json = name+ "_sam2USeq.json.gz"
    params:
        "-v GRCm38 -x 1000 -r -c 20"    
    threads:
        allThreads    
    log:
        name+ "_Sam2USeq.log"
    shell:
        "{java} -Xmx{allMemory} -jar {useq}/Sam2USeq {params} -f {input} "
        "-b {regionsForRC} -p {output.cs} -j {output.json} -n {name} &> {log} && "
        "cp {input}/*useq {output.useq} &>> {log} && "
        "echo [`date`] rule Sam2USeq: COMPLETE; echo" 
        
# QC, Convert the uniOb read coverage track to something that will play nicely with IGV and the UCSC genome browsers
rule USeq2UCSCBig:
    input:
        name+ "_uniObReadCov.useq"
    output:
        name+ "_uniObReadCov.bw"
    threads:
        allThreads    
    log:
        name+ "_USeq2UCSCBig.log"
    shell:
        "{java} -Xmx{allMemory} -jar {useq}/USeq2UCSCBig -u {input} -f -d {ucsc} &> {log} && "
        "echo [`date`] rule Useq2UCSCBig: COMPLETE; echo" 
